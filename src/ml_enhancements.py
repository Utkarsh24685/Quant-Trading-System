# -*- coding: utf-8 -*-
"""ML_enhancements.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S9LM5Vez0ziX9LlXcCZWels8fJsTVoMu

# Part 5: Machine Learning Enhancement (Leakage-Free)

This notebook improves the baseline trading strategy using a machine learning
filter while explicitly avoiding data leakage.

Only market-state and informational features are used.
Signal-defining features (EMA crossover logic) are excluded.

## Task 5.1: Problem Definition

Objective:
Predict whether a baseline trade will be profitable using only
market context and informational features.

Target:
- 1 → Profitable trade
- 0 → Non-profitable trade

Leakage Control:
- EMA indicators and position signals are excluded
- No forward-looking or signal-derived features are used
"""

import pandas as pd
import numpy as np

df = pd.read_csv("baseline_strategy_ml_ready.csv")
df['date'] = pd.to_datetime(df['date'])

df.head()

"""### Feature Selection (Leakage-Free)

Removed:
- EMA indicators
- EMA spread
- Position / signal columns

Kept:
- Regime labels
- Lagged returns
- Futures basis
- Option Greeks & IV features

"""

FEATURES = [
    'regime',
    'ret_lag_1',
    'ret_lag_2',
    'ret_lag_3'
]

TARGET = 'ml_target'

X = df[FEATURES]
y = df[TARGET]

"""Train/Test Split:
- First 70% → Training
- Last 30% → Testing
(Time-ordered, no shuffling)

"""

split = int(0.7 * len(df))

X_train, X_test = X.iloc[:split], X.iloc[split:]
y_train, y_test = y.iloc[:split], y.iloc[split:]

"""# MODEL TRAINING

### Model: XGBoost Classifier

- Handles non-linear relationships
- Robust to noisy financial features
- Suitable for tabular time-series data
"""

import os
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

XGB_MODEL_PATH = "xgboost_trade_classifier.json"

if os.path.exists(XGB_MODEL_PATH):
    print("Loading existing XGBoost model...")

    xgb = XGBClassifier()
    xgb.load_model(XGB_MODEL_PATH)

else:
    print("Training new XGBoost model...")

    xgb = XGBClassifier(
        n_estimators=300,
        max_depth=4,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        eval_metric="logloss"
    )

    xgb.fit(X_train, y_train)

    xgb.save_model(XGB_MODEL_PATH)
    print(f"XGBoost model saved to {XGB_MODEL_PATH}")

print("XGBoost Accuracy:", accuracy_score(y_test, xgb_preds))
print(classification_report(y_test, xgb_preds))

xgb.save_model("xgboost_trade_classifier.json")

"""## Model B: LSTM Classifier

The LSTM model is trained to predict trade profitability using
a sequence of past market-state features.

Input:
- Sequence length: Last 10 candles
- Features: Regime + lagged returns

Architecture:
LSTM → Dropout → Dense → Output

"""

from sklearn.preprocessing import StandardScaler
import numpy as np

SEQ_LEN = 10

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

def create_sequences(X, y, seq_len):
    Xs, ys = [], []
    for i in range(seq_len, len(X)):
        Xs.append(X[i-seq_len:i])
        ys.append(y.iloc[i])
    return np.array(Xs), np.array(ys)

X_seq, y_seq = create_sequences(X_scaled, y, SEQ_LEN)

split_seq = int(0.7 * len(X_seq))

X_train_seq, X_test_seq = X_seq[:split_seq], X_seq[split_seq:]
y_train_seq, y_test_seq = y_seq[:split_seq], y_seq[split_seq:]

import os
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dropout, Dense

LSTM_MODEL_PATH = "lstm_trade_classifier.keras"

if os.path.exists(LSTM_MODEL_PATH):
    print("Loading existing LSTM model...")
    lstm_model = load_model(LSTM_MODEL_PATH)

else:
    print("Training new LSTM model...")

    lstm_model = Sequential([
        LSTM(64, input_shape=(SEQ_LEN, X.shape[1])),
        Dropout(0.3),
        Dense(1, activation="sigmoid")
    ])

    lstm_model.compile(
        optimizer="adam",
        loss="binary_crossentropy",
        metrics=["accuracy"]
    )

    lstm_model.fit(
        X_train_seq,
        y_train_seq,
        epochs=15,
        batch_size=32,
        validation_split=0.2,
        verbose=1
    )

    lstm_model.save(LSTM_MODEL_PATH)
    print(f"LSTM model saved to {LSTM_MODEL_PATH}")

lstm_probs = lstm_model.predict(X_test_seq).flatten()
lstm_preds = (lstm_probs > 0.5).astype(int)

from sklearn.metrics import accuracy_score, classification_report

print("LSTM Accuracy:", accuracy_score(y_test_seq, lstm_preds))
print(classification_report(y_test_seq, lstm_preds))

lstm_model.save("lstm_trade_classifier.keras")

"""## ML-Enhanced Backtest

Trades are taken only when:
- Baseline strategy gives a signal
- ML model predicts profitability (confidence > 0.5)

We compare:
- Baseline strategy
- XGBoost-filtered strategy
- LSTM-filtered strategy

"""

split = int(0.7 * len(df))

df_train = df.iloc[:split].copy()
df_test  = df.iloc[split:].copy()

df_train.reset_index(drop=True, inplace=True)
df_test.reset_index(drop=True, inplace=True)

df_test['baseline_equity'] = (1 + df_test['strategy_return']).cumprod()

df_test['xgb_conf'] = xgb_probs
df_test['xgb_trade'] = (df_test['xgb_conf'] > 0.5).astype(int)

df_test['xgb_strategy_return'] = (
    df_test['strategy_return'] * df_test['xgb_trade']
)

df_test['xgb_equity'] = (1 + df_test['xgb_strategy_return']).cumprod()

SEQ_LEN = 10

df_test_lstm = df_test.iloc[SEQ_LEN:].copy()
df_test_lstm.reset_index(drop=True, inplace=True)

lstm_probs_aligned = lstm_probs[-len(df_test_lstm):]

df_test_lstm['lstm_conf'] = lstm_probs_aligned
df_test_lstm['lstm_trade'] = (df_test_lstm['lstm_conf'] > 0.5).astype(int)

df_test_lstm['lstm_strategy_return'] = (
    df_test_lstm['strategy_return'] * df_test_lstm['lstm_trade']
)

df_test_lstm['lstm_equity'] = (1 + df_test_lstm['lstm_strategy_return']).cumprod()

comparison.plot(
    figsize=(12, 6),
    title='Baseline vs XGBoost vs LSTM – ML Enhanced Backtest'
)

comparison = pd.DataFrame({
    'baseline_equity': df_test['baseline_equity'].iloc[SEQ_LEN:].values,
    'xgb_equity': df_test['xgb_equity'].iloc[SEQ_LEN:].values,
    'lstm_equity': df_test_lstm['lstm_equity'].values
})

comparison.tail()

# Columns we WANT to save
cols_to_save = [
    'date',
    'regime',
    'strategy_return',
    'baseline_equity',
    'xgb_conf', 'xgb_trade', 'xgb_strategy_return', 'xgb_equity',
    'lstm_conf', 'lstm_trade', 'lstm_strategy_return', 'lstm_equity',
    'avg_iv', 'iv_spread',
    'pcr_oi', 'pcr_vol',
    'delta_neutral_ratio', 'gamma_exposure',
    'ema_spread',
    'spot_return'
]

# Keep only columns that actually exist
cols_to_save = [c for c in cols_to_save if c in final_df.columns]

print("Saving columns:")
print(cols_to_save)

final_df[cols_to_save].to_csv(
    "nifty_ml_backtest_daily.csv",
    index=False
)